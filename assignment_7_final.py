# -*- coding: utf-8 -*-
"""Assignment_7_final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhHrKsKjadkYlpiivLTVkVOMu2-f6OZv
"""

from flask import Flask, request, jsonify, render_template
import joblib
import pandas as pd
import numpy as np
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer, PorterStemmer
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from autocorrect import Speller
import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# pip install autocorrect

df = pd.read_csv('1spam.csv', encoding='cp1252')
df

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()
spell = Speller(lang='en')


def preprocess(text):
    # Convert to lower case
    text = text.lower()
    # Remove stop words
    words = word_tokenize(text)
    words = [word for word in words if not word in stop_words]
    # Lemmatize words
    words = [lemmatizer.lemmatize(word) for word in words]
    # Stem words
    words = [stemmer.stem(word) for word in words]
    # Correct spelling mistakes
    words = [spell(word) for word in words]
    return ' '.join(words)


# Apply preprocessing to messages
df['message'] = df['message'].apply(preprocess)

# Split dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(
    df['message'], df['label'], test_size=0.2, random_state=42)

# Vectorize text using TF-IDF
tfidf = TfidfVectorizer()
X_train_tfidf = tfidf.fit_transform(X_train)
X_test_tfidf = tfidf.transform(X_test)

lr_model = LogisticRegression()
lr_model.fit(X_train_tfidf, y_train)
lr_score = lr_model.score(X_test_tfidf, y_test)
print("Accuracy of Logistic Regression Model: {:.2f}%".format(lr_score*100))


joblib.dump(lr_model, "spam_classifier.joblib")
joblib.dump(tfidf, "vectorizer.joblib")

# code to run flask application

# Load the model and vectorizer from files
model = joblib.load("spam_classifier.joblib")
vectorizer = joblib.load("vectorizer.joblib")

# Create a Flask web application
app = Flask(__name__)

# Define a route to serve the web page


@app.route("/")
def index():
    # Return the HTML from the file "index.html"
    return render_template("index.html")


# Define preprocessing functions
stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()
spell = Speller(lang='en')


def preprocess(text):
    # Convert to lower case
    text = text.lower()
    # Remove stop words
    words = word_tokenize(text)
    words = [word for word in words if not word in stop_words]
    # Lemmatize words
    words = [lemmatizer.lemmatize(word) for word in words]
    # Stem words
    # words = [stemmer.stem(word) for word in words]
    # Correct spelling mistakes
    words = [spell(word) for word in words]
    return ' '.join(words)

# Define a route to accept user input and return a prediction


@app.route("/predict", methods=["POST"])
def predict():
    # Get the user input
    message = request.form["message"]
    message = preprocess(message)
    print(message)
    # Preprocess the input
    message_vector = vectorizer.transform([message])

    # Make a prediction
    prediction = model.predict(message_vector)[0]

    # Return the prediction as JSON
    # return jsonify({"prediction": prediction})
    return render_template("index.html", prediction=prediction)


if __name__ == "__main__":
    app.run()
